{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6f3bcb7c-8b47-4033-8bf2-8f3fdf17d38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Dec  5 00:58:37 2023       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-12GB            Off| 00000000:03:00.0 Off |                    0 |\n",
      "| N/A   36C    P0               26W / 250W|      0MiB / 12288MiB |      1%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da48bfc5-d800-4efc-b6c2-84b8ceed1b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU:\n",
      "  CPU: Intel(R) Xeon(R) CPU E5-2680 v4 @ 2.40GHz\n",
      "  Architecture: X86_64\n",
      "CUDA available\n",
      "/home/zhou.he1/.local/lib/python3.9/site-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Running on 1 GPU(s) with 8 worker(s)---------------------\n",
      "Epoch [1/5]------------------------------------------------------------------------\n",
      "| Train Loss: 2.6379 | Train Acc: 0.3419 | Val Loss: 2.2612, Val Acc: 0.4013\n",
      "| Elapsed Time: 168.3404 s | Max GPU Memory Alloc: 1959.4707 MB\n",
      "Epoch [2/5]------------------------------------------------------------------------\n",
      "| Train Loss: 2.0147 | Train Acc: 0.4722 | Val Loss: 1.8101, Val Acc: 0.5250\n",
      "| Elapsed Time: 160.1430 s | Max GPU Memory Alloc: 1959.4722 MB\n",
      "Epoch [3/5]------------------------------------------------------------------------\n",
      "| Train Loss: 1.8259 | Train Acc: 0.5156 | Val Loss: 1.6800, Val Acc: 0.5383\n",
      "| Elapsed Time: 160.7226 s | Max GPU Memory Alloc: 1959.4731 MB\n",
      "Epoch [4/5]------------------------------------------------------------------------\n",
      "| Train Loss: 1.2214 | Train Acc: 0.6453 | Val Loss: 1.2316, Val Acc: 0.6402\n",
      "| Elapsed Time: 161.6456 s | Max GPU Memory Alloc: 1959.4741 MB\n",
      "Epoch [5/5]------------------------------------------------------------------------\n",
      "| Train Loss: 1.2085 | Train Acc: 0.6482 | Val Loss: 1.2190, Val Acc: 0.6451\n",
      "| Elapsed Time: 161.2071 s | Max GPU Memory Alloc: 1959.4751 MB\n",
      "\n",
      "total_time: 812.6894192695618\n",
      "best_valid_acc: 0.6451172319599363\n",
      "train_loss: [2.63790635148091, 2.0147399205473238, 1.825854827501865, 1.2213808214094137, 1.2085311142945516]\n",
      "train_acc: [tensor(0.3419, device='cuda:0', dtype=torch.float64), tensor(0.4722, device='cuda:0', dtype=torch.float64), tensor(0.5156, device='cuda:0', dtype=torch.float64), tensor(0.6453, device='cuda:0', dtype=torch.float64), tensor(0.6482, device='cuda:0', dtype=torch.float64)]\n",
      "valid_loss: [2.261227463416784, 1.8100944576225708, 1.6800238144050392, 1.2316015742714086, 1.2189923811889634]\n",
      "valid_acc: [tensor(0.4013, device='cuda:0', dtype=torch.float64), tensor(0.5250, device='cuda:0', dtype=torch.float64), tensor(0.5383, device='cuda:0', dtype=torch.float64), tensor(0.6402, device='cuda:0', dtype=torch.float64), tensor(0.6451, device='cuda:0', dtype=torch.float64)]\n",
      "epo_elapsed_time: [168.34043145179749, 160.1430013179779, 160.72262692451477, 161.6455512046814, 161.20708084106445]\n",
      "max_alloc: [1959.470703125, 1959.47216796875, 1959.47314453125, 1959.47412109375, 1959.47509765625]\n",
      "Figure(1200x500)\n",
      "Figure(1200x500)\n"
     ]
    }
   ],
   "source": [
    "!python p4_2_2__workers_main.py --num_nodes 1 --num_workers 8 --num_epochs 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcea33a-2bc9-423e-b3b3-e231aae88aad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
